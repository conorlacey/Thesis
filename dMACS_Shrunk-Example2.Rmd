---
title: "Portfolio 4"
author: "Conor Lacey"
date: '2023-03-17'
output: github_document
---

### Introduction

This portfolio will demonstrate how dMACS shrunk works with code. 

### Create invariant items 

```{r fake data}
set.seed(55555)

library(dmacs)

eta <- seq(-1000,1000, by = 10) #Generate true scores
load.R <- .6 #loading for the reference group
load.F <- 1.2 #loading for focal group
int.R <- 0 #intercept for reference group
int.F <- 1 #intercept for focal group

y.R <- load.R*eta + int.R #model-implied scores for reference group
y.F <- load.F*eta + int.F #model-implied scores for focal group

sd.pooled.test.num <- ((length(y.R)-1)*sd(y.R)) + ((length(y.F)-1)*sd(y.F)) 
sd.pooled.test.denom <- (length(y.R) - 1) + (length(y.F) - 1)
sd.pooled.test <- sd.pooled.test.num/sd.pooled.test.denom
```

### Calculate initial observed dMACS

The method I demonstrate here is the method created by Nye & Drasgow, (2011)

```{r dMACS}
item_dmacs(.6, #loading, R 
      1.2, #loading, F
      0, #intercept, R
      1, #intercept, F
      mean(eta), #mean (both groups)
      var(eta), #variance (both groups, but it would be the focal group if they didn't have the same variance)
      sd.pooled.test #pooled standard deviation (again, this is basically arbitrary)
      )
```

### Update Parameter 

Ok now I will define some function's from Bergh et al., (2021).

```{r functions}
get.dMACS <- function(outcome.R, outcome.F, eta = Eta) {
  lm.R <- lm(outcome.R ~ eta)$coefficients
  lm.F <- lm(outcome.F ~ eta)$coefficients
  load.R <- lm.R[2]
  int.R <- lm.R[1]
  load.F <- lm.F[2]
  int.F <- lm.F[2]
  integrand <- function(x){
    product<-(load.R*x + int.R) - (load.F*x + int.F)
    return((product^2)*dnorm(x,mean(eta), sd(eta)))
  }
  inside.sqrt<- integrate(integrand, (min(eta)-10000), (max(eta)+10000))$value
  sd.pooled.num <- ((length(outcome.R)-1)*sd(outcome.R)) + ((length(outcome.F)-1)*sd(outcome.F))
  sd.pooled.denom <- (length(outcome.R)-1) + (length(outcome.F)-1)
  sd.pooled <- sd.pooled.num/sd.pooled.denom
  sqrt(inside.sqrt)/sd.pooled
}

erfcinv <- function(x) qnorm(x / 2, lower.tail = FALSE) / sqrt(2)

pss <- function(x, par) {
  return((x > 0) * par[1] + (1 - par[1]) * pnorm(x, par[2], par[3]))
}

inverseCdf <- function(p, par) {

  thresh0 <- pss(0, par)
  thresh1 <- pss(0 + 1e-100, par)
  out <- numeric(length(p))

  idx1 <- p < thresh0 | p > thresh1 # where F(p) != 0
  idx0 <- p[idx1] >= thresh1 # where F(p) < 0

  out[idx1] <- par[2] - sqrt(2) * par[3] * erfcinv(2 * (par[1]*idx0 - p[idx1]) / (par[1] - 1))
  return(out)
}

postStat <- function(par) {
  # lower <- myQ(.025, par=par)
  # error(lower, 0.025, par) > error(0.1, 0.025, par)
  # diff <- 0.025 - pss(lower, par)
  # upper <- myQ(.975 - diff, par)
  # browser()
  # curve(pss(x, par), from = -2, to = 2, n = 2^12)
  lower <- inverseCdf(0.025, par)
  diff <- 0.025 - pss(lower, par)
  upper <- inverseCdf(0.975 - diff, par)
  if (upper == 0) upper <- upper + 1e-100
  diff <- 0.975 - pss(upper, par)
  lower <- inverseCdf(0.025 - diff, par)
  pss(upper, par) - pss(lower, par)
  me <- par[2] * (1 - par[1])
  return(c("lower" = lower, "upper" = upper, "model averaged" = me))
}

bf <- function(d, n, v0) {
  a <- 1 / sqrt(n * (v0 + 1))
  b <- n^2 * d^2
  c <- 2 * (n + 1 / v0)
  return(a * exp(b / c))
}

updatePar <- function(rho0, v0, N, ybar) {
  prec <- (N + 1 / v0)
  v1 <- 1 / prec
  c <- N * ybar
  mu1 <- v1 * c
  w <- bf(ybar, N, v0)
  rho1 <- rho0 / (rho0 + (1 - rho0) * w)
  return(c("ph0" = rho1, "mu" = mu1, "sd" = sqrt(v1)))
}
```


### Update Paramenter

```{r Update Parameter}
priorPH0  <- 0.5
sigmaSlab <- 1

# explicit
# datExplBlock1 <- subset(datExpl, ValenceBlock == "1" & Block == "1")$DV
# datExplBlock2 <- subset(datExpl, ValenceBlock == "1" & Block == "2")$DV

ybarExpl <- get.dMACS(y.R, y.F, eta)
nExpl <- length(y.R)

upMAExpl <- updatePar(priorPH0, sigmaSlab, nExpl, ybarExpl[1L])
ciMAExpl <- postStat(upMAExpl)

tbExplicit <- data.frame(t(c(upMAExpl, ciMAExpl)))
names(tbExplicit) <- c("ph0", "mu1", "sd1", "Lower", "Upper", "modelAveraged")

tbExplicit
```

Ta da! So we get the posterior mean dMACs estimate of .66 which is about the same as the original esimate calculated. Now all that's is left to do multiply this by the posterior probability of dMACS having a real effect which is 1 - Ph0(the probability that there is an effect of zero). 

```{r dMACS_Shrunk}
dMACS_Shrunk <- (1-tbExplicit[1])*tbExplicit[2]
dMACS_Shrunk
```

And there we have it! dMACS_Shrunk in action!